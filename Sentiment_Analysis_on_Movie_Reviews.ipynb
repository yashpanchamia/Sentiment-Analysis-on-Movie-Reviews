{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# For train data\n",
    "file = open(\"reviewstrain.txt\", \"r\") \n",
    "all_comments = file.readlines()\n",
    "all_comments[0][:-2]\n",
    "train_label = []\n",
    "train_data = []\n",
    "for comment in all_comments:\n",
    "    label = comment[0]\n",
    "    data = list(set(comment[2:-2].split()))\n",
    "    train_data.append(data)\n",
    "    train_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For test data\n",
    "file_test = open(\"reviewstest.txt\", \"r\") \n",
    "all_comments = file_test.readlines()\n",
    "test_label = []\n",
    "test_data = []\n",
    "for comment in all_comments:\n",
    "    label = comment[0]\n",
    "    data = list(set(comment[2:-2].split()))\n",
    "    test_data.append(data)\n",
    "    test_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(test_data, train_data, train_label, k):\n",
    "    predicted = []\n",
    "    for tes_data in test_data:\n",
    "        dictionary = {}\n",
    "        temp = []\n",
    "        for index,tra_data in list(enumerate(train_data)):\n",
    "            \n",
    "            # Calculate Distance\n",
    "            inter_c1_c2 = len(set(tes_data) - (set(tes_data)-set(tra_data)))\n",
    "            if inter_c1_c2 == 0:\n",
    "                distance = 1\n",
    "            else:\n",
    "                distance = 1/inter_c1_c2\n",
    "            \n",
    "            # Store dictionary with dist as key and labels as values\n",
    "            if distance not in dictionary:\n",
    "                dictionary[distance] = [train_label[index]]\n",
    "            else:\n",
    "                dictionary[distance].append(train_label[index])\n",
    "                \n",
    "        \n",
    "        sorted_keys = sorted(dictionary)\n",
    "        \n",
    "        if k == 1:\n",
    "            if len(dictionary[sorted_keys[0]]) == 1:\n",
    "                predicted.append(int(dictionary[sorted_keys[0]][0]))\n",
    "            else:\n",
    "                count_1 = dictionary[sorted_keys[0]].count('1')\n",
    "                count_0 = dictionary[sorted_keys[0]].count('0')\n",
    "                if count_0>count_1:\n",
    "                    predicted.append(0)\n",
    "                else:\n",
    "                    predicted.append(1)\n",
    "                    \n",
    "        else:\n",
    "            temp = 0\n",
    "            distances_to_traverse = []\n",
    "            for i in range(len(dictionary)):\n",
    "                temp+=len(dictionary[sorted_keys[i]])\n",
    "                distances_to_traverse.append(sorted_keys[i])\n",
    "                if temp>=k:\n",
    "                    break\n",
    "            l = []\n",
    "            for dist in distances_to_traverse:\n",
    "                l += dictionary[dist]    \n",
    "    \n",
    "            count_1 = l.count('1')\n",
    "            count_0 = l.count('0')\n",
    "            if count_0>count_1:\n",
    "                predicted.append(0)\n",
    "            else:\n",
    "                predicted.append(1)\n",
    "                    \n",
    "    return predicted\n",
    "\n",
    "\n",
    "answer = KNN(test_data,train_data,train_label,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy for k=5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.6\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predicted, real):\n",
    "    temp = 0\n",
    "    for p,r in zip(predicted, real):\n",
    "        if int(p)==int(r):\n",
    "            temp+=1\n",
    "            \n",
    "    return (temp/len(predicted))*100\n",
    "\n",
    "print(accuracy(answer,test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for k=5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 91, 136],\n",
       "       [ 61, 212]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label = list(map(int,test_label))\n",
    "answer = list(map(int,answer))\n",
    "\n",
    "confusion_matrix(test_label, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 3, accuracy = 66.0\n",
      "For k = 7, accuracy = 65.8\n",
      "For k = 99, accuracy = 61.133333333333326\n"
     ]
    }
   ],
   "source": [
    "length_of_each_data = len(train_label)//5\n",
    "\n",
    "for k in k_values:\n",
    "    \n",
    "    predicted_cv_final = [0]*len(train_label)\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        \n",
    "        start_index = length_of_each_data*(i-1)\n",
    "        end_index = length_of_each_data*i\n",
    "        \n",
    "        \n",
    "        \n",
    "        validation_data_cv = train_data [start_index : end_index]\n",
    "        validation_label_cv = train_label [start_index : end_index]\n",
    "\n",
    "        if i==1:\n",
    "            train_data_cv = train_data [end_index:]\n",
    "            train_label_cv = train_label [end_index:]\n",
    "        else:\n",
    "            train_data_cv = train_data[:start_index] + train_data[end_index:]\n",
    "            train_label_cv = train_label[:start_index] + train_label[end_index:]\n",
    "\n",
    "\n",
    "        predicted_cv = KNN(validation_data_cv, train_data_cv, train_label_cv, k)\n",
    "        \n",
    "        predicted_cv_final[start_index:end_index] = predicted_cv\n",
    "        \n",
    "    print(\"For k = {}, accuracy = {}\".format(k,accuracy(predicted_cv_final,train_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy & Confusion Matrix for k=3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.0\n"
     ]
    }
   ],
   "source": [
    "answer = KNN(test_data,train_data,train_label,3)\n",
    "print(accuracy(answer,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 83, 144],\n",
       "       [ 61, 212]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label = list(map(int,test_label))\n",
    "answer = list(map(int,answer))\n",
    "\n",
    "confusion_matrix(test_label, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our own distance function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For train data\n",
    "file = open(\"reviewstrain.txt\", \"r\") \n",
    "all_comments = file.readlines()\n",
    "all_comments[0][:-2]\n",
    "train_label = []\n",
    "train_data = []\n",
    "for comment in all_comments:\n",
    "    label = comment[0]\n",
    "    data = comment[2:-2]\n",
    "    train_data.append(data)\n",
    "    train_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For test data\n",
    "file_test = open(\"reviewstest.txt\", \"r\") \n",
    "all_comments = file_test.readlines()\n",
    "test_label = []\n",
    "test_data = []\n",
    "for comment in all_comments:\n",
    "    label = comment[0]\n",
    "    data = comment[2:-2]\n",
    "    test_data.append(data)\n",
    "    test_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinDistance(s1, s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  61.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import string\n",
    "def KNN(test_data, train_data, train_label, k):\n",
    "    predicted = []\n",
    "    for tes_data in test_data:\n",
    "        dictionary = {}\n",
    "        temp = []\n",
    "        for index,tra_data in list(enumerate(train_data)):\n",
    "            \n",
    "            temp_tra_data = tra_data.split()\n",
    "            tra_data = [w for w in temp_tra_data if w not in string.punctuation]\n",
    "            tra_data = \"\".join(tra_data)\n",
    "            \n",
    "            \n",
    "            temp_tes_data = tes_data.split()\n",
    "            tes_data = [w for w in temp_tes_data if w not in string.punctuation]\n",
    "            tes_data = \"\".join(tes_data)\n",
    "            \n",
    "            distance = levenshteinDistance(tra_data,tes_data)\n",
    "            distance = round(distance,1)\n",
    "            \n",
    "#             distance = distance_sequenceMatcher(str(tra_data),str(tes_data))\n",
    "            \n",
    "#             distance = round(distance,1)\n",
    "            \n",
    "            # Store dictionary with dist as key and labels as values\n",
    "            if distance not in dictionary:\n",
    "                dictionary[distance] = [train_label[index]]\n",
    "            else:\n",
    "                dictionary[distance].append(train_label[index])\n",
    "                \n",
    "        \n",
    "        sorted_keys = sorted(dictionary)\n",
    "        \n",
    "        if k == 1:\n",
    "            if len(dictionary[sorted_keys[0]]) == 1:\n",
    "                predicted.append(int(dictionary[sorted_keys[0]][0]))\n",
    "            else:\n",
    "                count_1 = dictionary[sorted_keys[0]].count('1')\n",
    "                count_0 = dictionary[sorted_keys[0]].count('0')\n",
    "                if count_0>count_1:\n",
    "                    predicted.append(0)\n",
    "                else:\n",
    "                    predicted.append(1)\n",
    "                    \n",
    "        else:\n",
    "            temp = 0\n",
    "            distances_to_traverse = []\n",
    "            for i in range(len(dictionary)):\n",
    "                temp+=len(dictionary[sorted_keys[i]])\n",
    "                distances_to_traverse.append(sorted_keys[i])\n",
    "                if temp>=k:\n",
    "                    break\n",
    "            l = []\n",
    "            for dist in distances_to_traverse:\n",
    "                l += dictionary[dist]    \n",
    "    \n",
    "            count_1 = l.count('1')\n",
    "            count_0 = l.count('0')\n",
    "            if count_0>count_1:\n",
    "                predicted.append(0)\n",
    "            else:\n",
    "                predicted.append(1)\n",
    "                    \n",
    "    return predicted\n",
    "\n",
    "\n",
    "answer = KNN(test_data,train_data,train_label,1)\n",
    "print(\"Accuracy = \",accuracy(answer,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 91, 136],\n",
       "       [ 56, 217]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label = list(map(int,test_label))\n",
    "answer = list(map(int,answer))\n",
    "\n",
    "confusion_matrix(test_label, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  64.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk_words = list(stopwords.words('english'))\n",
    "import string\n",
    "def KNN(test_data, train_data, train_label, k):\n",
    "    predicted = []\n",
    "    for tes_data in test_data:\n",
    "        dictionary = {}\n",
    "        temp = []\n",
    "        for index,tra_data in list(enumerate(train_data)):\n",
    "            \n",
    "            temp_tra_data = tra_data.split()\n",
    "            tra_data = [w for w in temp_tra_data if w not in string.punctuation]\n",
    "            tra_data = \"\".join(tra_data)\n",
    "            \n",
    "            \n",
    "            temp_tes_data = tes_data.split()\n",
    "            tes_data = [w for w in temp_tes_data if w not in string.punctuation]\n",
    "            tes_data = \"\".join(tes_data)\n",
    "            \n",
    "            distance = levenshteinDistance(tra_data,tes_data)\n",
    "            distance = round(distance,1)\n",
    "            \n",
    "#             distance = distance_sequenceMatcher(str(tra_data),str(tes_data))\n",
    "            \n",
    "#             distance = round(distance,1)\n",
    "            \n",
    "            # Store dictionary with dist as key and labels as values\n",
    "            if distance not in dictionary:\n",
    "                dictionary[distance] = [train_label[index]]\n",
    "            else:\n",
    "                dictionary[distance].append(train_label[index])\n",
    "                \n",
    "        \n",
    "        sorted_keys = sorted(dictionary)\n",
    "        \n",
    "        if k == 1:\n",
    "            if len(dictionary[sorted_keys[0]]) == 1:\n",
    "                predicted.append(int(dictionary[sorted_keys[0]][0]))\n",
    "            else:\n",
    "                count_1 = dictionary[sorted_keys[0]].count('1')\n",
    "                count_0 = dictionary[sorted_keys[0]].count('0')\n",
    "                if count_0>count_1:\n",
    "                    predicted.append(0)\n",
    "                else:\n",
    "                    predicted.append(1)\n",
    "                    \n",
    "        else:\n",
    "            temp = 0\n",
    "            distances_to_traverse = []\n",
    "            for i in range(len(dictionary)):\n",
    "                temp+=len(dictionary[sorted_keys[i]])\n",
    "                distances_to_traverse.append(sorted_keys[i])\n",
    "                if temp>=k:\n",
    "                    break\n",
    "            l = []\n",
    "            for dist in distances_to_traverse:\n",
    "                l += dictionary[dist]    \n",
    "    \n",
    "            count_1 = l.count('1')\n",
    "            count_0 = l.count('0')\n",
    "            if count_0>count_1:\n",
    "                predicted.append(0)\n",
    "            else:\n",
    "                predicted.append(1)\n",
    "                    \n",
    "    return predicted\n",
    "\n",
    "\n",
    "answer = KNN(test_data,train_data,train_label,5)\n",
    "print(\"Accuracy = \",accuracy(answer,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 84, 143],\n",
       "       [ 37, 236]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label = list(map(int,test_label))\n",
    "answer = list(map(int,answer))\n",
    "\n",
    "confusion_matrix(test_label, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
